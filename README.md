# *Highload Архитектура*

Расчётно-пояснительная записка

Домашнее задание по курсу Highload

Выполнено студентом 3-го семестра: Ширшов А.С.

  

---

## **О Сервисе**

Reddit - сервис, сочетающий в себе черты социальной сети и форума, где пользователи могут размещать информацию и заниматься её непосредственным обсуждением.

  

## **MVP**

- Регистрация и авторизация на сервисе

- Возможность создания форумов, постов

- Просмотр постов других пользователей

- Возможность комментирования постов

- Система голосования

## **Целевая аудитория**

- 430 млн активных пользователей Ежемесячно

- Сервис наиболее популярен среди населения возрастной группы от 25 до 29 лет. На неё приходится примерно 23% пользователей.

- Следом идёт возрастная группа от 18 до 24 лет. Они составляют 21% пользователей, что показывает популярность сервиса среди молодёжи.

- Основная часть пользователей приходится на Северную Америку и Европу

### Статистика

- https://aliexpress.inform.click/10-statisticheskih-dannyh-reddit-kotorye-vy-dolzhny-znat-v-2021-godu-infografika/

- https://foundationinc.co/lab/reddit-statistics/

  

## **Расчёт нагрузки**

- Месячная аудитория: 430 млн пользователей

- Суточная аудитория: 52 млн пользователей

    (Данные были взяты из статистического анализа, приложенного пунктом выше)

- Средний размер хранилища пользователя


Будем считать пользователь пользователь оставляет по комментарию в день под каждым интересующим его форумом. Длина комментария в среднем от 20 до 80 символов. Пусть пользователь подписан на 10 форумов. Также пользователь может иметь свой форум, где может выкладывать собственные посты. Допустим пользователь делает иногда фотографии и выкладывает их в сервис с периодичностью 2 недели.

| Комметарий    | Кол-во комментариев       | Пост (Изображение)      |
|:-------------:|:-------------------------:|:-----------------------:|
| 0.1 Kb        | 10 * 14                   |         ~750 kb         |

Выходит: 0,89 Mb каждые две недели выходит от пользователя. Сервис существует с 2005 года. То есть если пользователь зарегистрировался примерно в 2013 году, (средняя дата), то результат выходит: 0,89 * 2 * 12 * 8 = 170,88 Mb

- Среднее кол-во действий пользователя в день

По статистике в среднем пользователи проводят на сайте 10 минут 23 секунды. 

 1. Пользователи в основном листают ленту, состоящую из постов, подписанных форумов, а также рекомендации. Также пользователь может оставить комментарий под постом. За 10 минут пользователь тратя по 10 секунд на пост и иногда оставляя комментарии в среднем просмотрит около 40 постов и напишет 2-5 комментариев. Также учтём, что пользователь оценит хотя бы половину постов, ибо это сделать намного проще, чем оставить коментарий, а просматривает он в основном интересующие его форумы. 
 2. Также пользователи могут создавать форумы и выкладывать собственные посты. Если личных форумов на пользователя приходится немного за всё время использования, то для постов воспользуемся моделью пользователя описанного выше (пост раз в две недели).
 3. Пользователи могут просматривать чужие профили. Если считать, что пользователь будет смотреть профиль пользователя, выложившего заинтересовавший его пост (считаем, что комментарий -> интерес), то выйдет 2-5 профиля в день.

 4. Пользователь может искать форумы по интересующей его тематике, часто это связано с актуальными новостями в обществе, то есть по 1 поисковому запросу в день.
 
 Выходит в день:

| Посты (Просмотр)             |  Комментариии       | Профили   | Оценки | Поиск  | Пост (Выложить)|
|:----------------------------:|:-------------------:|:---------:|:------:|:------:|:--------------:|
| 40 (Лента загружается 1 раз) | 2-5                 |     2-5   | 20     |1       | 0,0714         |

### **Технические метрики**

- Размер хранения

1) У пользователей есть профили, где находится краткая информация о них, а также персональный аватар.

| Аватар        | Информация о пользователе | Суммарные данные |
|:-------------:|:-------------------------:|:----------------:|
| 750 KB        | 1 Kb                      |         0.75 Mb  |

2) Сервис разбивается на форумы, где можно размещать посты, комментировать их, а также оценивать пост по системе лайк/дизлайк. Также посты могут содержать изображения и видео. Так как форумы разделяются на крупные(> 500 тыс подписок), средние(> 10 тыс подписок) и локальные(< 10 тыс подписок), возьмём за среднее значение форум с 50 тыс. участников. Такой форум должен существовать примерно несколько лет, чтобы собрать такую аудиторию. Возьмём значение 2 года. В день для поддерджания аудитории выкладывается по 2-3 поста. Каждый пост в среднем содержит изображение, реже небольшой видеоматериал, и подпись от 20 до 80 символов, и каждый пост содержит около 20 комментариев и в среднем 300 голосов.
Тогда:

| Комметарий    | Кол-во комментариев       | Пост (с медиасодержимым)| Кол-во постов                |
|:-------------:|:-------------------------:|:-----------------------:|:----------------------------:|
| 0.1 Kb        | 20                        |         ~1.5 Mb         | 2.5 поста * 365 дней * 2 года|

*Содержимое стобца пост уже включает голоса

*Также форум содержит информацию о нём, но она много меньше его содержимого, поэтому в подсчёт не входит.

Выходит средний форум содержит около 1825 постов по 20 комментариев в каждом. Получается: 1825 * (1,5 +20*0.001) = 2920 Mb на форум ~ 2,85 Gb

По статистике реддит содержит примерно около 2 млн форумов: 2,85 Gb * 2 000 000 ~ 1113 Tb. Так как за расчёт мы брали не являющимся крупным форум срок существования которому два года, а время существования сервиса уже больше 15 лет, то данное количество данных следует увеличить примерно в 5 раз (Число меньше, чтобы опустить неактивные форумы, созданных за время существования сервиса). -> 5569 Tb

- Сетевой трафик

Если возьмём полученные данные выше, что пользователь в день загружает 170,88 Mb, а суточная аудитория составляет 52 млн пользователей, то выходит 170,88 * 52 000 000 = 100,4 Gb/s

- RPS

Если возьмём полученные данные выше, что пользователь совершает около 28,0724 действий в день, а суточная аудитория составляет 52 млн пользователей, то выходит 16895 RPS 

## Логическая схема 

Выделим следующие сущности:

- Пользователь (User)
- Форум(Thread)
- Пост(Post)
- Комментарии (Сomments)
- Оценка поста (Post_Vote)
- Оценка комментария (Comment_Vote)
- Подписки (Subscriptions)
- Сессии (Sessions) - для хранения текущей сессии пользователя

![alt text](https://i.ibb.co/mBYGWD8/image.png)

## Физическая схема

![alt text](https://i.ibb.co/1LzgCHp/image.png)

### Основные сущности
Для хранения большинства данных используем реляционную СУБД PostgreSQL. Она является отличным решением в области SQL DB и она обладает высокой надёжностью создания объявленных ранее сущностей (Пользователь, Пост ...) и дальнейшей записи/чтения данных. Для выдерживания пользовательской нагрузки применим шардирование для сущностей лайков и постов. Для комментариев применим же и реплику и шардирование. Так у нас будет 1 master на запись и 2 slave на чтение. Использование реплицирования позволит нам существенно увеличить скорость на чтение комментариев под пользовательскми постами. Для данного проекта также реализуем микросервисную архитектуру и вынесем наиболее нагруженные части(Комментарии и Оценки) в отдельные микросервисы, что также должно повысить производительность и усточивость системы. Также из статьи про развитие архитектуры Reddit можно найти про использование memcached, используемый в репликах на чтение. https://www.infoq.com/presentations/reddit-architecture-evolution/

### Индексы
Использование индексов также существенно ускоряет поиск данных в базе данных. Т.к количество необходимых индексов достаточно велико, то выделим основные из них.

- Индексы к таблице Subscriptions (Она представляет собой промежуточную таблицу для отношения Many-to-Many)
- Индексы к таблице Comments, связанные с полями parent и path (Необходимы для выстраивания деревьев комментариев под постом и ответами на них)
- Индексы к таблице Posts с полями votes и created для возможности сортировки постов на форуме.
- Индексы по nickname пользователей для нахождения необходимого юзера.
### Хранение медиафайлов

Для хранения изображений будем пользоваться Amazon S3 хранилищем. Хранение видеоконтента будем осуществлять на собственных серверах в связи со объёмом хранения данных и скоростью передачи для стриминга.

### Хранение сессий пользователей

Для решения данной проблемы воспользуемся одним из самых популярных решений key-value storage Redis.

### Объёмы хранилищ

Ранее мы расчитали необходимое количество памяти для хранения данных о форумах и постах.

Добавим данные о пользователе. Также воспользуемся рассчитаннами ранее значениями. (Так как нет информации об общем количестве ползователей, для расценки возьмём MAU). Ранее было получено, что профиль пользователя составляет из себя в основном его аватар. Вес профиля был оценён в 750 kb, тогда выходит: 430 000 000 * 0,75 mb = 307 Tb

Сессии пользователей состоят из id пользователей и времени окончании сессии. 4(int) + 13(timestamp) = 17 bytes. Сессии пользователей ограничим дневной длительностью -> 17 * 52 000 000 = 843 Gb

Таблицы PSQL
 
```

User -> id(4) + nickname(20) + display_name(20) + about(256) + email(50) + gender(4) + media_link(256) + password(256) = 866B -> 866 * 430 000 000 = 346,8 GB

Subsription -> id(4) + user_id(4) + thread_id(4)

- Thread -> id(4) + user_id(4) + slug(256) + title(256) + category(4) = 524B -> 524 * 2 200 000 = 1,07 GB

- Post -> id(4) + thread_id(4) + [message(40000)](https://www.reddit.com/r/help/comments/nykedi/how_many_characters_can_you_have_in_a_reddit_post/) + user_id(4) + created(13) + media_link(256) + votes(4) + comments(4) = 40 289B -> 40 289 * 15 000 * 150 = 84,4 GB

- Post_vote -> id(4) + post_id(4) + user_id(4) + vote(4) = 16 B -> 16 * 25 000 * 150 * 15 000 = 838,2 GB

- Comment_vote -> id(4) + post_id(4) + user_id(4) + vote(4) = 16 B -> 16 * 15000 * 150 * 1400 * 700 = 32,09 TB

- Comment -> id(4) + post_id(4) + [message(10000)](https://www.reddit.com/r/redditdev/comments/gpccr5/what_is_the_max_character_length_a_reddit_comment/) + user_id(4) + created(13) + is_edited(1) + votes(4) + parent(4) + path(2*4) (Будем считать, что на один комментарий в среднем только ответ/reply, то есть нет поддерева ответов) = 10042 B -> 10042 * 15000 * 150 * 1400 = 28,77 TB

```

* На реддите выбор более 2-х позиций, поэтому тип bool не подходит.
* Будем использовать SHA-256 для паролей
* Ранее уже был приведён примерный расчёт, необходимого объёма данных, основанный чисто на статистических данных, здесь же применим подчёт хранимых данных, опираясь на построенную схему. Также мы получили, что объём храненимых данных составляет 5569 TB, что меньше полученных здесь данных, это связано с тем, что при подсчёте таблиц не учитывается размер медиасодержимого, который как раз и составляет большую часть данных.
* Про кол-во комментариев под постами (1400)

![alt text](https://i.ibb.co/KydfSnD/image.png)

* Про кол-во голосов (25000)

![alt text](https://i.ibb.co/bbzFLQG/image.png)



## Технологии

### Frontend

Используем общепринятые технологии. HTML + CSS + JS/TS. Здесь выбор скорее всего в пользу TypeScript, так как наличие статической типизации, а также возможность нахождения ошибок в коде до сборки способствует повышению производительности разработчиков. Для уменьшения размера файлов и поддержки старых версий браузеров воспользуемся webpack и babel. Также необходимо выбрать библиотеку и фреймворк, здесь остановимся на React и Next.js, так как использование React даст нам поддержку Virtual DOM, а Next.js использование такой технологии как SSR, что должно сделать работу пользователя с приложением более комфортной.

### Backend

Здесь выбор в сторону Go, так как встроенный в язык scheduler позволяет более эффективно управлять многопоточными операциями. Также для повышения отказоустойчивости, а также удобной замене и добавлению новых модулей мы будем использовать микросервисную архитектуру. Общение между микросервисами будем организовывать при помощи gRPC. gRPC использует протокол protobuf, обеспечивая меньший размер сообщения и более высокую скорость сериализации чем jsonRPC.

### Mobile

IOS - Swift

Android - Kotlin

Здесь также выбор в сторону общепринятых решений. Большое коммунити разработчиков, грамотная и полная документация, наличие большего количества библиотек является весомым преимуществом по сравнению с такими новыми языками, как Dart, Flutter. Также для разработки можно было сделать выбор в сторону React Native, но использование выбранных языков позволяет непосредственно работать с android и IOS плюсом являются официально поддерживаемыми компаниями Google и Apple.

### Балансировка

В качестве балансировщика нагрузки будем использовать nginx. Алгоритм для балансировки round robin.

## Cхема проекта

![alt text](https://i.ibb.co/R4znC6k/image.png)

## Cписок серверов

По подсчитанным ранее данным мы должны справляться с нагрузкой в 100 GB/s. Для этого воспользуемся сетевыми картами на 40 GB. Также мы должны выдерживать 16895 RPS. По данным об обработке nginx https запросов видим, что нам хватит для реализации сервера с 4 СPU. https://www.nginx.com/blog/testing-the-performance-of-nginx-and-nginx-plus-web-servers/ Оперативной памяти возьмём 16 GB на сервер. С учётом необходимости более 2-ух серверов для выдерживания нагрузки сети возьмём 4 сервера с 2 СPU, тем самым покрыв оба параметра. Для обеспечения отказоустойчивости добавим  реплики к уже имеющимся серверам получим в итоге 8 серверов.

![alt text](https://i.ibb.co/841DfZz/image.png)

Для бэкенда надо учитывать обязательно связку с бд, так количество rps будет сильно зависеть от того насколько у нас оптимизированы запросы. 

Для данных целей возьмём пару серверов с 16СPU и 32 GB ОЗУ. Также добавим реплики. Итого 4 сервера.


Для выдерживания пользовательских сессий необходимо взять как минимум 4 сервера с 256 GB оперативной памяти (Мы используем Redis и ранее было посчитано, что нам необходимо 843 GB). Также для выдерживания такой нагрузки возьмём процессор с 64 ядрами. Также для обеспечения отказоустойчивости возьмём реплики. Итого 8 серверов.

Для хранения данных порядка 5500 TB (Медиаконтент) и быстрой работе с ними потребуется использование большого количества ssd дисков. Если в один сервер мы можем уместить 8 SSD по 8 TB -> 64 TB, то выходит нам потребуется 86 сервера для хранения медиасодержимого.

Для хранения бд, так как мы вынесли комментарии и оценки в отдельные микросервисы. Для комментариев (28,77 TB) достаточно будет сервера с 4 SSD по 8 TB, но так как мы используем slave для чтения, то надо ещё выделить два таких же сервера для чтения данных. Итого 3 сервера плюс реплики -> 6 серверов

Для хранения голосов выделим сервер с 5 SSD по 8 TB. Остальные же сущности составляют в сумме много меньше данных, возьмём для них 2 SSD по 512 GB. Также не забываем про реплики выходит 2 сервера с 5 SSD по 8 TB и 2 сервера 2 SSD по 512 GB.

Для рассмотренных выше пунктов возьмём процессоры с 32 ядрами и 64 GB ОЗУ на сервер. 


### Расположение
Исходя из статистической выкладке представленной ниже, можно сделать вывод, что основной трафик, порядка 65%, приходится на США, остальной же раномерно распределяется на весь мир. Тогда распределим имеющуюся сетевую нагрузку, оставим 3 балансировщика с репликами (6 всего), оставшиеся два расположим ближе к Океании так как там находится большая часть пользователей не из США. Возьмём в качестве расположения Сан-Франциско (США) и Сидней (Австралия).

![alt text](https://i.ibb.co/S3hnDPw/original-319.png)

### Итог

| Part                  | CPU     | RAM      | Memory       | Number of servers (*2 из-за двух центров)|
|:---------------------:|:-------:|:--------:|:------------:|:----------------------------------------:|
| Балансировка          |  4      |  16 GB   |  128 GB SSD  |                     8                    |
| Backend               |  16     |  32 GB   |  256 GB SSD  |                 4 * 2 = 8                |
| Sessions              |  64     |  256 GB  |  2 TB SSD    |                 8 * 2 = 16               |
| MediaContent          |  32     |  64 GB   |  64 TB SSD   |                86 * 2 = 172              |
| PostgreSQL Comments   |  32     |  64 GB   |  32 TB SSD   |                 6 * 2 = 12               |
| PostgreSQL Votes      |  32     |  64 GB   |  40 TB SSD   |                 2 * 2 = 4                |
| PostgreSQL Main       |  32     |  64 GB   |  512 GB SSD  |                 2 * 2 = 4                |


